{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138e3a81-ac90-4dc7-9078-ad6402acf3d8",
   "metadata": {
    "id": "138e3a81-ac90-4dc7-9078-ad6402acf3d8"
   },
   "source": [
    "# Benchmark for bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed945dbd-18cd-414f-ac8a-95683ad432b1",
   "metadata": {
    "id": "ed945dbd-18cd-414f-ac8a-95683ad432b1"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1fff1d5-47e8-4b63-9fd2-e1e30168a7a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26640,
     "status": "ok",
     "timestamp": 1650886811810,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "f1fff1d5-47e8-4b63-9fd2-e1e30168a7a8",
    "outputId": "812537ec-27d2-4b01-dac0-294cd4fad391"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/abauville/Notes_Gaussian_processes.git\n",
    "# !cp /content/Notes_Gaussian_processes/bayes_lib.py .\n",
    "# !pip install gpytorch\n",
    "# !pip install botorch\n",
    "from datetime import datetime\n",
    "\n",
    "from bayes_lib import ExactGPModel, train_hyper_params, get_x_new, run_experiment\n",
    "import torch\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.constraints import Interval\n",
    "import botorch\n",
    "from botorch.test_functions.synthetic import Hartmann\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9569d7b-225b-4a96-ba84-eb4dd428639b",
   "metadata": {
    "executionInfo": {
     "elapsed": 11917,
     "status": "ok",
     "timestamp": 1650862791141,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "b9569d7b-225b-4a96-ba84-eb4dd428639b"
   },
   "source": [
    "## Define the ground truth, baseline and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d954da6-44cf-4255-9b5f-e78e17429a0a",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650886816312,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "9d954da6-44cf-4255-9b5f-e78e17429a0a"
   },
   "outputs": [],
   "source": [
    "def gt_func(x):\n",
    "    \"\"\"Ground truth function: negative hartmann 6\n",
    "    The Bayes opt library we use aims to maximize functions by default.\n",
    "    We use the negated function to effectively minimize it, i.e. argmin(f(x)) = argmax(-f(x))\n",
    "    \"\"\"\n",
    "    hart = Hartmann()\n",
    "    return - hart.evaluate_true(x)\n",
    "\n",
    "def error_gap(current_best):\n",
    "    \"\"\"Returns the absolute difference between the global minimum of the hartmann 6 function\n",
    "    and the current best value\n",
    "            Error gap := |min f(x*) -  current best|\n",
    "    \"\"\"\n",
    "    hart = Hartmann()\n",
    "    return abs(current_best - (- hart.optimal_value))\n",
    "\n",
    "def baseline_model(gt_func, n_iter, n):\n",
    "    \"\"\"A model that attempts to maximize by picking n random sample and keeping the minimum value. \n",
    "    The process is repated over n_iter iterations\n",
    "    Parameters\n",
    "    ============\n",
    "    n_iter: int\n",
    "        number of iterations\n",
    "    n: int\n",
    "        number of samples drawn at each iteration\n",
    "        \n",
    "    Returns\n",
    "    ============\n",
    "    array of shape (n_iter,)\n",
    "        contains the max of the function discovered so far at each iteration\n",
    "    \"\"\"\n",
    "    results = -np.ones(n_iter)\n",
    "    results[0] = gt_func(torch.randn(n*6).reshape(-1,6)).max()\n",
    "\n",
    "    for i in range(2, n_iter):\n",
    "        results[i] = max(results[i-1], gt_func(torch.randn(n*6).reshape(-1,6)).max())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b8771-7632-450e-9f78-662bc5d591cc",
   "metadata": {
    "id": "874b8771-7632-450e-9f78-662bc5d591cc"
   },
   "source": [
    "## Run the Bayesian optimization\n",
    "\n",
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a9239a9-3aeb-4191-9d87-96f7cf741fff",
   "metadata": {
    "executionInfo": {
     "elapsed": 11905,
     "status": "ok",
     "timestamp": 1650886828211,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "2a9239a9-3aeb-4191-9d87-96f7cf741fff"
   },
   "outputs": [],
   "source": [
    "n_exp = 10                  # number of experiments\n",
    "n_iter = 200                # number of iterations\n",
    "print_period = 5           # results are printed every print_period iteration\n",
    "n_train_ini = 20            # number of initial training examples\n",
    "\n",
    "\n",
    "\n",
    "error_gaps = np.zeros([n_exp, n_iter]) # array to store the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d08be-9c7a-44bd-91f5-415133b26afe",
   "metadata": {
    "id": "964d08be-9c7a-44bd-91f5-415133b26afe"
   },
   "source": [
    "### Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a07469-1ee4-4134-8212-dba15e6bc874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 532129,
     "status": "error",
     "timestamp": 1650887360306,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "45a07469-1ee4-4134-8212-dba15e6bc874",
    "outputId": "3dd4ce78-cdd3-49de-947f-94aee5fbf378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "030/200: 3.18763, 3.05602, -0.87051\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/nr_cpjbj1sv1ckm03fv704qc0000gn/T/ipykernel_75188/765240086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Experiment {i_exp: 02d}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"=============\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0merror_gaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train_ini\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Save intermediate results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/58/nr_cpjbj1sv1ckm03fv704qc0000gn/T/ipykernel_75188/3068852582.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(gt_func, n_iter, n_train_ini)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# ============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mEI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpectedImprovement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_x_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbest_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/GoogleDrive/My Drive/00_Data_science/Notes_Gaussian_processes/bayes_lib.py\u001b[0m in \u001b[0;36mget_x_new\u001b[0;34m(aquisition_func, model, best_f, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mXinit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batch_initial_conditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maquisition_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_restarts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     batch_candidates, batch_acq_values = gen_candidates_torch(\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0minitial_conditions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXinit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0macquisition_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maquisition_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/generation/gen.py\u001b[0m in \u001b[0;36mgen_candidates_torch\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, optimizer, options, callback, fixed_features)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for i_exp in range(n_exp):\n",
    "    print(f\"Experiment {i_exp: 02d}\")\n",
    "    print( \"=============\")\n",
    "    error_gaps = run_experiment(gt_func, n_iter, n_train_ini)\n",
    "    \n",
    "    # Save intermediate results\n",
    "    # ============================\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%s\")\n",
    "    np.save(\"timestamp_error_gaps\", error_gaps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "483a0ea1-ffc5-4394-b285-8721d3132ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022042521091650888590'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9e45a-01ec-4fb6-bb94-dd6dfe4000f6",
   "metadata": {
    "id": "d5b9e45a-01ec-4fb6-bb94-dd6dfe4000f6"
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xVqAknNGF5qc",
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "aborted",
     "timestamp": 1650887360303,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "xVqAknNGF5qc"
   },
   "outputs": [],
   "source": [
    "def plot_series(X, label=''):\n",
    "    means = np.mean(X,0)\n",
    "    stds = np.std(X,0)\n",
    "    ax.plot(means, label=label)\n",
    "    ax.fill_between(np.arange(n_iter), \n",
    "                    means + 2.0*stds, \n",
    "                    means - 2.0*stds, \n",
    "                    alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a2c85-ad5b-419b-883d-8adadefc3b7d",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "aborted",
     "timestamp": 1650887360305,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "2b4a2c85-ad5b-419b-883d-8adadefc3b7d"
   },
   "outputs": [],
   "source": [
    "baseline_results = np.array([baseline_model(n_iter, int(1e3)) for i in range(n_exp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hozzi9GAH__Z",
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "aborted",
     "timestamp": 1650887360305,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "Hozzi9GAH__Z"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=[7,7])\n",
    "plot_series(baseline_results, label='baseline')\n",
    "plot_series(error_gaps, label='BayesOpt')\n",
    "ax.set_yscale('log')\n",
    "plt.legend()\n",
    "plt.title(\"Hartmann 6D function minimization\")\n",
    "plt.ylabel(\"error gap\")\n",
    "plt.xlabel(\"func. evaluations\")\n",
    "plt.savefig(\"hartmann_min.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xJUBRzVGAIkW",
   "metadata": {
    "id": "xJUBRzVGAIkW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "04_BayesOpt_Benchmark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
